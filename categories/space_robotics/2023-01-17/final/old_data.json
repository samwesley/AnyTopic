{"date": "2023-01-17", "category": "sr", "articles": {"0": {"text": "17-01-2023 | Fluke | Test & Measurement\n\nFluke has released the Fluke 5560A High-Performance Multi-Product Calibrator, which offers the widest electrical workload coverage and highest accuracy.\n\nMeeting the demand at the high-end of the multi-product calibrator market, the device sits neatly in the company's product range under the high-accuracy, multi-function 5730A calibrator created for calibrating 8.5-digit resolution DMMs. The device is an excellent solution for calibrating up to 6.5-digit DMMs.\n\nThe device features a large 7\" display with an intuitive touchscreen for ease of use, Visual Connection Management terminals and an optional accessory for efficient DMM calibration with minimal or no lead changes. The rugged and portable calibrator can also be automated using MET/CAL Calibration Management Software.\n\nAmong the benefits to users of the device are minimal training needs, lower maintenance, and the ability to calibrate a wider range of equipment using a single calibrator. These all contribute to substantial reductions in the cost of ownership for calibration laboratories. It is protected against expensive damage induced by incoming voltages or overload conditions.\n\nIn its quest to provide calibration laboratories with the next generation of advanced tools, the company has also released the 5550A Performance Multi-Product Calibrator, enhancing the highly popular multi-product 5522A to offer a better match for a customer's existing DMM workloads. It greatly improves the accuracy supplied by the 5522A 5.5-digit DMMs and provides greater functionality. Offering an intuitive GUI, it can calibrate the most popular handheld DMMs with increased TURs and clamp meters to 1500A with continuous current output (30A).\n\nThe 5540A Multi-Product Calibrator is another new addition to enhance the company's improved range. It expands the capabilities of the 5502A with better performance levels, making it an excellent solution for on-site or mobile calibration of the most demanding field instrumentation workloads. It is perfect for calibrating handheld 4.5-digit resolution DMMs with increased TURs and clamp meters to 1500A with continuous current output. Improvements in comparison to the 5502A include an increase from 20A to 30A of continuous current output and cutting waiting times during heavy usage. A wider range of thermocouple types and a new easy-connect thermocouple connector widens the temperature workload coverage of the calibrator. The 5540A can be fully calibrated with a Fluke 8588A 8.5-digit Reference Multimeter plus one shunt for the highest current range.\n\nWim Sibon, Fluke Calibration technical sales manager for Electrical Calibration in Europe, said: \"In recent years, we have experienced increasing demand from laboratories for greater accuracy in their calibrators while also wanting multi-product solutions that free up bench space and keep costs down. The 5560A calibrator provides exactly what the market requires and will deliver a significant boost to the productivity of calibration laboratories around the world. This will enable our customers to cope with the demand for more accurate measurements but with a less experienced workforce.\n\n\"Fluke Calibration is committed to providing calibration laboratories with the widest workload calibration capabilities, and our latest additions to the range will enable lab technicians to expand their existing workloads with confidence. The 5502A and 5522A have been the workhorses of calibration laboratories for many years, and we are delighted to take their capabilities to a whole new level with the 5540A multi-product and 5550A performance multi-product calibrators. Backed by more than 50 years of continuous engineering improvements, our comprehensive range of powerful tools are the result of lifelong dedication from some of the best calibration experts in the world. At Fluke Calibration, we are passionate about measurement science.\"", "title": "High-performance multi-product calibrator offers increased bench space", "keywords": ["space", "current", "laboratories", "highperformance", "dmms", "fluke", "offers", "increased", "multiproduct", "calibrator", "continuous", "calibration", "device", "bench", "range"], "link": "https://www.electropages.com/2023/01/high-performance-multi-product-calibrator-offers-increased-bench-space", "skip": "false"}, "1": {"text": "Once upon a time, Alphabet (the parent company of Google) invested heavily in robotics. A decade ago, it acquired Boston Dynamics, maker of highly sophisticated robots like BigDog, along with seven other robotics firms. In theory, the tech giant would use that extensive portfolio to build\u2026 well, something.\n\nBut Alphabet never took its robotics efforts mainstream, and it sold off Boston Dynamics in 2017. Now, it\u2019s laying off workers from Intrinsic, the current name for its robotics offshoot. The division is relatively small, and the actual layoffs will impact around 40 workers, or 20 percent of its staff.\n\n\u201cThis decision was made in light of shifts in prioritization and our longer-term strategic direction,\u201d a spokesperson told TechCrunch. \u201cIt will ensure Intrinsic can continue to allocate resources to our highest priority initiatives, such as building our software and AI platform, integrating the recent strategic acquisitions of Vicarious and OSRC (commercial arm Open Robotics), and working with key industry partners. While incredibly tough to do, we believe this decision is necessary for us to continue our mission.\u201d\n\nThe layoffs are yet another sign that some of the most prominent names in tech, including Alphabet, Meta, Amazon and Salesforce, are cost-cutting and retrenching in the face of a possible recession. Amazon is reportedly slicing back \u201cunprofitable\u201d business units, including the devices unit responsible for the Alexa voice-activated assistant and various consumer hardware products. Over at Meta, CEO Mark Zuckerberg is vigorously defending his massive spending on an ecosystem of virtual reality (VR) and augmented reality (AR) products known collectively as the \u201cmetaverse,\u201d despite widespread company layoffs and institutional shareholders begging him to keep costs under control.\n\nThis latest round of layoffs at Alphabet aside, robotics also remains an area of focus for the technology industry as a whole. Tesla seems dedicated to producing a humanoid robot designed to handle \u201cboring, repetitive and dangerous\u201d work, and manufacturers are always looking for ways to automate production via increasingly sophisticated machines. Whether or not Alphabet (finally!) brings a robot product of some sort to the mainstream, robotics as a field isn\u2019t going away anytime soon.", "title": "Alphabet Robotics Division Cuts Workers", "keywords": ["tech", "alphabet", "layoffs", "products", "cuts", "sophisticated", "robot", "reality", "robotics", "strategic", "workers", "division"], "link": "https://www.dice.com/career-advice/alphabet-robotics-division-cuts-workers", "skip": "false"}, "2": {"text": "k-Space Associates, Inc. announced the launch of its newest thin film metrology tool, the kSA XRF. It measures film thickness for materials that are too thin for reliable optical measurements. This technique has been proven to measure semiconductor and dielectric layers on glass panels, wafers, and susceptors for applications in solar, power, and other thin film devices.\n\nk-Space CEO Darryl Barlett stated that \u201cwe developed the kSA XRF while helping one of our existing customers measure dielectric coatings that couldn\u2019t be measured using traditional optical methods. The XRF measures dielectric coatings below 100 nanometers and can be used by makers of glass panels, solar panels, MOCVD carriers and other products. It\u2019s a superior and more scalable option than existing tools and is easily installed into conveyor lines.\u201d\n\nThe kSA XRF uses an X-ray source, detector, and proprietary software to measure the X-ray emission spectrum, which is then used to calculate film thickness in real-time. It measures the appropriate atomic species based on the customer\u2019s unique coating formula and measurement needs. The kSA XRF can be configured for a standalone benchtop setup or over a conveyor for in-line inspection and manufacturing process control.\n\nAccording to CEO Barlett, \u201cthe kSA XRF allows users to characterize and monitor their thin film coatings during production, thereby increasing yield and reducing costs.\u201d", "title": "k-Space Launches Its Newest Thin Film Metrology Solution", "keywords": ["launches", "dielectric", "used", "xrf", "kspace", "measures", "film", "panels", "newest", "solution", "measure", "coatings", "metrology", "xray", "ksa"], "link": "https://www.novuslight.com/x_N12666.html", "skip": "false"}, "3": {"text": "Northrop Grumman Corporation\u2019s (NYSE: NOC) Long Duration Propulsive ESPA (LDPE)-3A spacecraft launched successfully today in support of the USSF-67 mission. This spacecraft helps advance rapid access to space for the U.S. Space Force and marks the third successful launch in the LDPE program.\n\nThe LDPE-3A was built using Northrop Grumman\u2019s ESPAStar, providing rapid access to space by maximizing the available volume inside a launch vehicle. This bus carries hardware for five independent missions, eliminating the need for each mission to wait for a future launch opportunity.\n\n\u201cFrom conception and development of next-generation space technology, like ESPAStar, to on-orbit command and control, we are prepared to support the full lifecycle of our customer\u2019s missions throughout the ever-evolving threat environment,\u201d said Troy Brashear, vice president, national security systems, Northrop Grumman.\n\nNorthrop Grumman also designed, developed and implemented the command and control, and mission execution software system for the LDPE program. The software system uses a common baseline across multiple programs, putting more capability in the hands of customer operators at a lower cost.\n\nThe ESPAStar product employs a customized version of a standard ESPA ring, providing added propulsion, power and avionic subsystems. A SpaceX Falcon Heavy launch vehicle will deliver LDPE-3A to near-geosynchronous Earth orbit for a one-year mission life.\n\nUSSF-67 is the third mission for the LDPE program. The Northrop Grumman-built LDPE-1 launched aboard the STP-3 mission in December 2021 and LDPE-2 aboard the USSF-44 mission in November 2022. Northrop Grumman will continue to deliver future ESPAStar spacecrafts, mission systems engineering, ground software systems and hardware platforms for critical USSF missions.\n\nNorthrop Grumman is a technology company, focused on global security and human discovery. Our pioneering solutions equip our customers with capabilities they need to connect, advance and protect the U.S. and its allies. Driven by a shared purpose to solve our customers\u2019 toughest problems, our 90,000 employees define possible every day.", "title": "Northrop Grumman-built LDPE-3A Satellite to Support US Space Force National Security Mission", "keywords": ["space", "force", "security", "ldpe3a", "launch", "support", "grumman", "software", "systems", "national", "mission", "northrop", "espastar", "grummanbuilt", "satellite", "ldpe"], "link": "https://www.geospatialworld.net/news/northrop-grumman-built-ldpe-3a-satellite/", "skip": "false"}, "4": {"text": "HONG KONG, Jan. 16, 2023 /PRNewswire/ -- Agilis RoboticsTM (Agilis), a leading developer of flexible robotic instruments that support endoscopic surgery through natural orifices of the body (e.g. along the gastrointestinal tract and in the bladder), has recently completed the second round of live animal testing using its proprietary robot. Dr. Jason Y.K. Chan, the co-founder of Agilis RoboticsTM , conducted the test with the firm's second-generation device on a live pig specimen and successfully removed artificial tumors using the en-bloc resection of bladder tumor (ERBT) technique. The test results met expectations, demonstrating promising results for the accuracy, safety, and efficacy of the firm's medical robotic system.\n\nDrawing on the advice of surgeons in earlier experiments, the research team has made several technical improvements to the original system that increased the efficiency of the surgery.\n\nThe 2nd generation prototype system has been optimized for more streamlined surgical control\n\nThe Agilis RoboticsTM system is a surgical robotic solution designed for endoscopic surgery. The system features a set of flexible surgical robotic instruments, a positioning cart and a surgeon's control chair. The flexible robotic instruments, with a diameter of less than 2.8 mm, can grip and cut away tumor tissue to remove it in its entirety.\n\nThe second-generation prototype system used in this test includes several improvements over the original system. With a smaller footprint, the updated positioning cart is 50% smaller, making it highly compact and easily positioned in the operating room.\n\nSecond, the newly developed endoscope holder offers the surgeon great flexibility for positioning the endoscope and robotic instruments. During operation, the surgeon can move the endoscope with ease using just one hand in thanks to the holder's sensor. The holder includes an automatic locking mechanism that prevents the unit from moving around freely, streamlining the surgeon's work and improving the procedure's safety.\n\nThe surgical tools have also been improved in this prototype iteration, allowing the surgeon to visualize the surgical field beyond the instruments more clearly and increase its load capacity to meet more demanding requirements. The electrosurgical knife instrument was also improved to enable bipolar diathermy, which substantially enhances tissue cutting effectiveness in bladder tumor resection. The most notable improvements are made to the controls and mechanical transmission in terms of precision and reduced control latency. This gives the surgeon a more intuitive and responsive control experience compared with manual operation. In addition to the controls, the team has also made substantial improvements to the system's ergonomic design and training simulator.\n\nNext, the company will test the system in animals for upper and lower gastrointestinal (GI) endoscopic submucosal dissection (ESD). This will be a major milestone for the company, demonstrating their potential within the sizeable market for GI diseases.\n\nAgilis RoboticsTM invited prominent gastroenterology and hepatology specialist Dr. Peter Chan Chun Wing to evaluate the system before its entry into the digestive tract market. Dr. Chan has almost 20 years of medical specialty practice, focusing on endoscopy and GI surgery. Dr. Chan is listed as a colonoscopy provider to the Colorectal Cancer Screening Programme of the Hong Kong Department of Health, offering pre-screening advice and colonoscopies for eligible individuals.\n\nAs the first internal medicine physician to use the system, Dr. Chan not only carried out ev-vivo tissue resection tests but also offered guidance on the system's potential for the GI market. He foresees the system's accessibility in general endoscopy clinics and centers, which is crucial to making the system widely adopted throughout healthcare institutions.\n\nAgilis RoboticsTM is challenging convention with its unmatched intuitiveness as minimally invasive endoscopic procedures are rapidly evolving\n\nA large number of new minimally invasive endoscopic techniques, including EMR (endoscopic mucosal resection) and ESD, have emerged to combat the increased detection of submucosal tumors, early cancers, and precancerous lesions in the digestive tract, which is a positive outcome due to rise in health awareness among the general population. By eliminating external incisions and promoting quick recovery, the practical use of these techniques has improved patient outcomes and decreased discomfort.\n\nEndoscopic minimally-invasive interventional techniques have evolved quickly in recent years and are becoming more important in the treatment of digestive disorders.\n\nInterventional procedures are more popular with patients as they are less invasive and require a shorter hospital stay. By enabling complete excision of diseased tissue while maintaining the normal function of the digestive tract, the approach can reduce the risk of post-operative complications such as infection associated with surgical operations (e.g., major surgery such as open-heart and open-abdomen).\n\nPatients who received endoscopic surgery recover quickly and stay in the hospital for a much shorter time\u2014usually 2 to 3 days or less\u2014before being discharged. The cost of treatment is only 1/3 to 1/2 of a general surgery. Industry insiders have said that although general surgery costs between 20,000 and 40,000 yuan, endoscopic minimally-invasive procedures can be managed for as little as 20,000 yuan.\n\nIn contrast to previous prototype tests, the company invited laypeople with no medical professionals to observe. They briefly used a virtual training simulator and then carried out tissue dissection in an ex-vivo tissue model.\n\nParticipants commented, \"The Agilis surgical robot is remarkable, even for an unskilled learner, as it can already remove artificial tumors from ex-vivo tissue after around 20 minutes of training with the simulator.\" The visitors claimed that the technology is simple to use and requires little training. Doctors skilled in endoscopic procedures must be able to pick up the skills quickly. They also expressed optimism about the device's commercialization potential.\n\nThe Agilis system also aims to support training using artificial intelligence (AI). Empirical endoscopic imaging is used in the AI system for deep learning to enhance the operator's surgical training. The learning curve for performing en-bloc tumor resection should be greatly reduced, as compared to manual ESD operations which are only performed by surgeons with extensive experience.\n\nA US$100 million firm focused on creating robotic equipment for endoscopic surgery\n\nSurgical robots in laparoscopy, orthopedic surgery, neurosurgery, vascular intervention, and other specialties are now popular topics in China. Businesses, however, need to think about how to break through the bottleneck of technological innovation in light of the highly competitive market.\n\nSeveral challenges have been identified in the course of developing robots for endoscopic surgery. For example, general endoscope working channels (2.8\u20133.7mm in diameter), require considerable flexibility to adapt to the changing shape as the endoscope travels through the narrow passageways within human body, resulting in high demands for the size and ergonomic design of the overall system.\n\nAgilis RoboticsTM is the first company to develop such a robotic system to overcome these challenges. The company has created a surgical robotic device that can seamlessly integrate with existing surgical procedures, notably for the GI and urological systems, to boost surgical efficiency and reduce the learning curve for endoscopic surgery. The firm's robotic instruments are totally flexible and has achieved a range of technological achievements.\n\nAs a kind of natural orifice transluminal endoscopic surgery (NOTES), endoscopic surgery is distinct from laparoscopy and requires a notably different set of technological skills. Major global players such as Johnson & Johnson, Intuitive Surgical, and Medtronic have developed their own surgical robotic systems, however none are working with the approach of utilizing conventional endoscopes and their working channels. Presently, R&D for NOTES is focused on the bronchial sector in China, none of which has received approval for use in the country as well.\n\nAccording to the US-based business consulting firm Frost & Sullivan, the global NOTES robot market is expected to grow at a CAGR of 88.2% from 2016 to 2026, maintaining significant growth, and is on track to reach 12.53 billion yuan by 2026 from 457 million yuan in 2020.\n\nThere is still room for growth in the market for endoscopic surgery robots for the urology and digestive systems. As the first Chinese business to build an endoscopic surgery robot, Agilis RoboticsTM has a head start on the competition in the market with a product that is already taking shape and has plans for pre-clinical testing.\n\nThe second-generation prototype used has optimized the structure and integration of the firm's flexible robot instruments in many ways. \"Our next step is to improve the robotics control and console's design and control features in a move to further improve surgical accuracy and efficiency,\" Agilis RoboticsTM revealed. The company is planning for next iteration prototype testing, and expects to complete the first human trial in the coming two years.\n\nIn June 2022, Agilis RoboticsTM closed its Series A fundraising. Joe Hui, co-founder and CFO, said that the advanced prototype will be delivered to The University of Hong Kong-Shenzhen Hospital in the second quarter of this year for additional testing. The company will also wrap up its NMPA testing in the third quarter of 2023 and then start a PRE-B round of funding with a minimum investment of US$10 million. The COVID-19 outbreak last year prevented investors from visiting to Hong Kong for test and experience the system in Series A roadshows. Now, in an effort to entice investors, the company has established a special Series A+ of US$5 million.\n\nView original content to download multimedia:https://www.prnewswire.com/news-releases/agilis-roboticstm-completes-new-round-of-live-animal-trials-with-miniaturized-robotic-instruments-for-endoscopic-surgery-301721505.html\n\nSOURCE Agilis Robotics Limited", "title": "Agilis RoboticsTM Completes New Round of Live Animal Trials with Miniaturized Robotic Instruments for Endoscopic Surgery", "keywords": ["miniaturized", "trials", "roboticstm", "endoscopic", "surgical", "company", "round", "surgery", "instruments", "agilis", "prototype", "system", "tissue", "completes", "robotic", "live"], "link": "https://www.biospace.com/article/releases/agilis-roboticstm-completes-new-round-of-live-animal-trials-with-miniaturized-robotic-instruments-for-endoscopic-surgery/", "skip": "false"}, "5": {"text": "In the suburbs of Kikuyu in Kiambu county, two young men are fiddling with wires and electric cables in their workshop, their grandmothers' former granary.\n\nMoses Kiuna, 29, and his cousin David Gathu have been doing this since they were children. They dismantle toys, radios and TV sets despite the spankings their fiddling attracted from their parents. Today, however, their tinkering is a lot more advanced.\n\nThe cousins are making robots that can assist people with disabilities perform simple tasks without assistance, and they already have two prototypes under their belt.\n\nTheir desire to create assistive technology came about in 2009, when they decided to try and help a classmate who had been born without a hand.\n\n\"We had a friend who was a congenital amputee and had one hand. We would see him struggle to write, eat and do other things that other children did with ease. It's then that we began asking ourselves how we could help him, and others, move from being dependent to independent persons,\" Kiuna said.\n\nTheir early experiences developed into an insatiable appetite for robotics, and they haven't looked back since.\n\nThe self-taught innovators began studying the science behind how the brain sends signals to the nervous system for motor activity to occur. Armed with this knowledge, they developed a robotic prosthetic that functions like a human hand to aid people who've lost arms due to accidents, illnesses or congenital disabilities.\n\nThe assistive device is worn on the head and back of the affected person to enhance communication between the brain and the prosthetic arm.\n\n\"The gadget uses brain signals received from the headset receiver and converts the user's intentions into actions performed by the robotic arm,\" Gathu explained.\n\n\"Decisions are transmitted by electric currents from one cell to another and are translated into various movements.\"", "title": "Young robotics create limbs for the disabled", "keywords": ["signals", "disabled", "gathu", "young", "fiddling", "brain", "prosthetic", "hand", "electric", "limbs", "robotics", "create", "kiuna", "robotic", "help"], "link": "https://www.the-star.co.ke/news/big-read/2023-01-17-young-robotics-create-limbs-for-the-disabled/", "skip": "false"}, "6": {"text": "A preflight light micrograph of a typical terrestrial tardigrade of the Milnesium genus seen at 40X Boothby Lab.\n\nA preflight light micrograph of a typical terrestrial tardigrade of the Milnesium genus seen at 40X magnification.\n\nThe objective of the Using Water Bears to Identify Biological Countermeasures to Stress during Multigenerational (Cell Science-04) investigation is to characterize the molecular biology of short term and multigenerational survival in the space environment by identifying genes that are required for adaptation and survival in high stress environments.\n\nImage courtesy of Boothby Lab. NASA ID: jsc2021e019949 jsc2021e019949 (5/29/2021) \u2013 larger image\n\nAstrobiology, extremophile,", "title": "Preflight Picture Of A Space-Bound Tardigrade", "keywords": ["stress", "survival", "micrograph", "typical", "preflight", "seen", "tardigrade", "terrestrial", "picture", "multigenerational", "milnesium", "spacebound"], "link": "https://astrobiology.com/2023/01/preflight-picture-of-a-space-bound-tardigrade.html", "skip": "false"}, "7": {"text": "Robots have been around for decades, but they\u2019ve been mostly stupid. They were either remotely controlled by humans or ran fixed scripts that allowed for virtually no latitude in terms of how they operated or what they did. Even though I was born in the year Robby the Robot became famous, the robots I grew up with weren\u2019t anything like Robby. They were about as smart as an old toaster.\n\nFortunately, that\u2019s changing. Robotics has advanced considerably over the last decade, partially thanks to the leading work Nvidia has done with autonomous vehicles, much of which translated into autonomous robotics. This year at CES, the top robots all seemed to have Nvidia brains, starting with a robotic tractor from John Deere and ending with Gl\u00fcxKind, an AI-powered baby stroller I want to buy for my aging dog.\n\nLet\u2019s talk about the Nvidia-powered robots at CES this week. We\u2019ll close with my Product of the Week, a wireless microphone that may keep me from getting into a fight on my next plane trip.\n\nJohn Deere Autonomous Tractor\n\nJohn Deere won the Best of Innovation award for its robotic tractor.\n\nJohn Deere Fully Autonomous Tractor | Image Credit: Deere & Company\n\nI grew up working on a farm. While driving a tractor was fun at first, it got tedious very quickly.\n\nThe heat and the repetition of driving in long rows were broken up only by the excitement of an equipment failure or the potential for a grizzly death should I fall asleep and fall off the tractor. That actually happened years later to the head of my division at IBM, who died when he fell off his tractor into a plow.\n\nJohn Deere\u2019s tractor won\u2019t get bored, tired, or die, so farmers can work on other things that need doing, given that staffing farms has become a big problem of late. Historically, robots weren\u2019t affordable on farms because labor was cheap. But you can\u2019t get those workers now, and getting locals to work on a farm is just as difficult.\n\nSo, if farmers want to keep operating, they need to automate, suggesting the farm of the future may be run entirely by increasingly intelligent robots and robotic equipment. So, this tractor may be critical to ensuring we have food on our tables in the future.\n\nAgrist Harvesting Robot\n\nAnother robot was from Agrist. I\u2019m not a fan of this one mainly because it was built to harvest bell peppers and bell peppers trigger my gag reflex. Just the smell of the things makes me feel ill. Still, if I had to harvest bell peppers (clearly one of my concepts of hell), I\u2019d appreciate a robot like this that kept my hands, nose, and tongue well away from the horrid things.\n\nSometimes you have to grow stuff you don\u2019t like, and this robot would assure me that if I still had a farm \u2014 which thankfully I don\u2019t \u2014 I could grow bell peppers and harvest them without ever getting that close to the darn things.\n\nSeriously, this robot is designed to work in indoor factory farms, which will be crucial to the survival of countries being badly impacted by climate change and losing the ability to farm as a result. Robots like this will be critical to sustaining humanity as the climate makes outdoor agriculture obsolete.\n\nSkydio Scout Drone\n\nDrones were also covered, with the Skydio drone standing out for its Scout drone.\n\nSkydio is a fascinating drone company. It even has a docked drone solution that reminds me of the old Green Hornet TV show. Can you imagine having one of these on your car so you can check what has caused the traffic jam you are stuck in? Or envision a police officer on a high-speed chase being able to launch one of these and have it autonomously and secretly follow the suspect, so they didn\u2019t have to risk life and limb chasing them in a car.\n\nSkydio drones are used in law enforcement, fire and rescue, power line inspection, construction, transportation, telecommunications, and defense.\n\nSkydio is a powerful company with an increasingly powerful set of autonomous products that may save your life one day, making this potentially one of the most important products launched at CES this year.\n\nGl\u00fcxKind \u2018Ella\u2019 AI-Powered Stroller\n\nI was looking for a powered stroller for my aging dog just a few weeks ago. When the dog gets tired on walks, we put her in a stroller, but pushing the thing up hills gets old. When my wife walks all three of our dogs alone, managing the stroller at the same time has become tedious and potentially unsafe.\n\nWhen empty, the Gl\u00fcxKind Ella stroller will follow you (I don\u2019t want to imagine a runaway with a baby in it). When occupied, it\u2019s battery-assisted to go up hills where my wife often struggles (I\u2019m currently her solution for going up hills).\n\nGl\u00fcxkind was named a CES 2023 Innovation Awards Honoree for its \u201cElla\u201d smart stroller. | Image Credit: Gl\u00fcxkind Technologies\n\nSadly, its current configuration won\u2019t work for my dog. Otherwise, I\u2019d probably order one. But trying to teach a 14-year-old dog to sit up in a stroller like a baby is a non-starter, though it would likely give others a bit of a shock when we walked by. Still, for parents with several children or walking their dog and kid at the same time, this powered stroller could be a winner.\n\nNow, if they\u2019d just come up with a pet configuration, I\u2019d be in.\n\nNeubility Delivery Robot\n\nThe Neubility self-driving robot, named Neubie, is one of the new delivery robots coming to market.\n\nI\u2019m a bit concerned about this class of robots. In trials, kids and some adults often abuse and break into these robots when in use. The Neubie is bigger and more robust than many I\u2019ve seen, but I speculate it may need some kind of defense or high-speed escape capability to work in the real world.\n\nThe onboard cameras should catch and record anyone that harms it, but it may be a while before people just leave the thing alone to do its job. For this reason, Neubility is smartly targeting golf courses where the robot can be better protected. Places like resorts, hospitals, and factories will be where robots like this can operate most successfully.\n\nI\u2019ll wait to see if they develop one with a built-in taser before I put a lot of faith in delivery robots outside of controlled environments like golf courses and resorts.\n\nStill, once accepted and protected, robots in this class will likely make delivery to homes by humans a thing of the past, better assure you are home to receive the delivery and make life much harder for porch pirates, whom I hate with a newly found passion after this past Christmas.\n\nSeoul Robotics LV5 Control Tower for Autonomous Parking\n\nSeoul Robotics showcased a Level 5 control tower, an interesting alternative to the typical way autonomous cars are currently configured. It uses infrastructure external to the vehicle to manage the automobile, potentially enabling any current-generation car with Level 2 technology that is connected to that grid to operate autonomously.\n\nThis variant is interesting because, rather than thinking of autonomous cars like they are now, it thinks of them more like how an aircraft traffic controller does by monitoring all the cars in range and directing from a central resource. Eventually, this technology could replace things like traffic lights, effectively moving them into the vehicle when it is being driven by humans and making them invisible to people riding in autonomous cars.\n\nNot only could this approach be much cheaper than putting this technology in every car, but it would also shift maintenance from the car owner to the government, which may maintain it better, though this isn\u2019t always a given.\n\nIt could also help ensure fewer catastrophic problems and allow older cars to better interoperate with newer autonomous vehicles while providing a viable low-cost upgrade for those that wanted to make recent cars that are currently not autonomous work as if they were. This is arguably the most innovative approach to the autonomous car problem I\u2019ve seen, and I\u2019m fascinated by it.\n\nWhill Autonomous Wheelchair\n\nFinally, Whill presented its autonomous wheelchair designed for people with limited mobility and sight. Aging or partially disabled folks who also can\u2019t see well are pretty much dependent on others because the white cane approach doesn\u2019t work in wheelchairs.\n\nWinner of the Best of Innovation award in the accessibility category, this wheelchair has unique high-traction tires and a rear bin for packages or groceries. It looks a bit like something out of a science fiction movie.\n\nWith a range of 12 miles, the ability to climb over 3-inch objects like curbs, and very high stability for rough streets, this could be ideal for aging seniors and those with sight and mobility problems. At 5.5 mph, it is anything but blazing fast, but if you have a mobility and sight problem, you probably don\u2019t want blazing fast.\n\nWeighing in at 250 pounds, it is lighter than many motorized solutions for those with limited mobility, and its autonomous capabilities provide independence that some people can\u2019t get any other way.\n\nWrapping Up\n\nThis list of robots at CES is not exhaustive, but I realized that most of the robots I looked at had Nvidia brains, so I figured I\u2019d use that as a theme for this column. The autonomous robot revolution is just beginning, with the hope we never go so far as to make the book Robopocalypse real.\n\nOver the next decade, these will be coming out at an increasing pace, and Nvidia has placed itself at the heart (well, maybe more at the brain) of these efforts. Eventually, we may be like George Jetson and have a Rosie-like maid that is autonomous, robotic, and with just the right level of snark.\n\nAt CES, I saw our robotic future. I can\u2019t wait until I have my own Rosie!\n\nMutalk VR Microphone\n\nBefore Christmas, I took my last trip of the year to New York. Before takeoff on the return flight, I had to do a radio interview over the phone. While the person next to me was okay with this, the guy in front of me was not and seemed to be about to punch me out because I was talking too loudly. I have a trained media voice, and it carries a long way.\n\nHaving a solution I could use when doing these things could be a lifesaver, particularly if we get to the point where we are making inflight phone calls and don\u2019t want to piss off or accidentally entertain everyone else on the plane with our conversations \u2014 let alone accidentally share confidential or personal information.\n\nThe Mutalk VR microphone was one of two products launched at CES that can contain your voice when speaking.\n\nI\u2019m picking the Mutalk because it was also designed to work with a VR rig which, given I play in VR, made it more attractive to me than its counterpart, the mask by Skyted, which was far larger and explicitly designed for inflight use. Frankly, I\u2019d be fine with either, and I must admit the full Mutalk rig might also be a bit much on a plane.\n\nIn the end, having something I could use for calls in areas with lots of ambient noise or when I need to speak loudly might get me punched out would be a godsend. So, the Mutalk leakage voice suppression microphone is my Product of the Week.\n\nThe opinions expressed in this article are those of the author and do not necessarily reflect the views of ECT News Network.", "title": "The Hottest Robots at CES Had Nvidia Brains", "keywords": ["farm", "nvidia", "ces", "work", "stroller", "hottest", "robots", "id", "autonomous", "robot", "tractor", "brains", "robotic"], "link": "https://www.technewsworld.com/story/the-hottest-robots-at-ces-had-nvidia-brains-177653.html", "skip": "false"}, "8": {"text": "Reddit Vote Share 0 Shares\n\nThe rapid increase of computational power and accessibility of computations have enabled a wide range of applications in computer vision and graphics. As a result, it is now possible to perform complex tasks like object detection, facial recognition, and 3D reconstruction in a short amount of time. Especially in the 3D domain, advancements in computer vision and graphics have allowed for the development of computer-based games, proof-of-concept 3D movies and animation, and options for virtual and augmented reality experiences. Furthermore, many applications in computer vision and graphics are close to being or have already been addressed with the help of deep learning and artificial intelligence.\n\nThese methods are based on artificial neural networks, which are used to learn complex patterns in data. Deep learning networks are hierarchical, meaning they are composed of multiple layers, with each layer learning a certain pattern. The learning process can be either supervised, meaning that labeled data is used to train the model, or unsupervised, which means that no labeled data is given for the training process. Once trained, the model can make predictions about data it has not seen before. In this sense, prediction is not strictly limited to the definition of its term. It relates to a large number of operations like object detection, object/entity classification, multimedia generation, point cloud compression, and much more.\n\nUsing these neural networks to address problems in the 3D domain can be tricky, as it requires more computational power and attention than in the 2D domain. One important task is related to 3D editing and the human interpretability of geometric parameters.\n\nEasing the 3D editing or customization process can be important for gaming or computer graphics applications. People interested in gaming probably know the detail of the customization that some editors can provide while creating a personalized avatar in games, from sport to action. Have you ever wondered how much time it takes to set up all these characteristics on the developer\u2019s side? Defining all those characteristics can take weeks or, worst case, months.\n\nGood news comes from research work presented in this article which shines a light on this problem and proposes a solution to automatize this process.\n\nThe proposed framework is depicted in the figure below.\n\nThe objective is to recover an editable 3D mesh from an input item represented as a 3D point cloud or a 2D sketch picture. To do this, the authors create procedural software that enforces a set of form constraints and is parameterized by controls that are easy for humans to understand. After teaching a neural network to infer the program parameters, they can generate and recover an editable 3D shape by running the program. This application has straightforward controls in addition to structural data, leading to consistent semantic portion segmentation by building.\n\nSpecifically, the program supports three parameters: discrete, binary, and continuous. The disentanglement of the shape parameters guarantees accurate control over the object characteristics. For instance, we can isolate the seat\u2019s shape from the other parts of a chair. Hence, modifying the seat will not impact the geometry of the remaining parameters, such as the backrest or the legs.\n\nTo obtain editing flexibility, mesh primitives such as spheres or planes are created and modified according to the user\u2019s needs. Two curves guide the generation of the final shape: a one-dimensional curve describing a path in the 3D space, and a two-dimensional curve, representing the profile of the shape.\n\nDefining curves in this way enables a rich variety of combinations, specified not only by the curves themselves but also by the attachment points, which are the points at which two curves are connected to each other. These points can be defined by a scalar floating value from 0 to 1, where 0 represents the beginning, and 1 is the end of the curve.\n\nBefore feeding the parameters to the program for the final 3D shape recovery, an encoder-decoder network architecture is exploited to map a point cloud or sketch input to the parameter representation.\n\nThe encoder embeds the input into a global feature vector. Then, the vector embeddings are fed to a set of decoders, each with the scope of translating the input into a single parameter (disentanglement).\n\nGeoCode can be used for various editing tasks, such as interpolation between shapes. An example is shown in the figure below.\n\nThis was the summary of GeoCode, a novel AI framework to address the 3D shape synthesis problem. If you are interested, you can find more information in the links below.\n\nCheck out the Paper, Github, and Project. All Credit For This Research Goes To the Researchers on This Project. Also, don\u2019t forget to join our Reddit Page, Discord Channel, and Email Newsletter, where we share the latest AI research news, cool AI projects, and more.", "title": "Meet GeoCode: An Artificial Intelligence Technique For 3D Shape Synthesis Using An Intuitively Editable Parameter Space", "keywords": ["using", "intuitively", "program", "editing", "learning", "shape", "geocode", "curves", "parameters", "data", "intelligence", "3d", "input", "space", "meet", "technique", "parameter", "graphics", "synthesis"], "link": "https://www.marktechpost.com/2023/01/16/meet-geocode-an-artificial-intelligence-technique-for-3d-shape-synthesis-using-an-intuitively-editable-parameter-space/", "skip": "false"}}}
block 1: Unless the driver can do something, the trolley will kill them all.The only option open is to turn the trolley onto a side track, killing only one person tied there; however, that would be intentional murder.This dilemma exists in many versions and has been asked for centuries by philosophers as a thought experiment to explore deontological (doing what is right) vs utilitarian (consequentialist) ethics.Summary: In this article, Mark Coeckelbergh examines how self-driving cars should handle lethal traffic situations and whether that question is even worth asking. He looks at our reaction to robots from Mary Shelley's Frankenstein through modern time where we have humanoid robots serving humanity but also attempting to take over power from humans. He looks at real world applications of robotics and ethical dilemmas concerning autonomy and safety of robotic systems which he believes should be explored now before it’s too late.
block 2: This article provides an overview of the moral dilemmas posed by self-driving cars and explores how cross-cultural differences can be taken into account when developing robotic solutions. It examines potential ethical challenges, such as attribution and distribution of responsibility, and poses questions including whether robots need morality and if they can have moral agency or responsibility.
block 3: Summary: In the article, Mark Coeckelbergh, a professor of philosophy at the University of Vienna, examines how self-driving cars might handle traffic situations involving difficult decisions such as deciding whether to kill one or five individuals in a hypothetical trolley problem. He looks at how humans have conceptualized robots and AI as part of a larger framework and considers what robot ethics should be about as these technologies become more advanced.
block 4: It was the first time a pedestrian had been killed by an autonomous vehicle on a public road.The person who ultimately should be held accountable, according to some accounts, is neither the passenger nor its real-time supervisor— both of whom were in the car and thus not able to react quickly enough— but rather those further away such as Uber’s engineers and operators or even those responsible for regulating traffic?Summary: Robots have traditionally been viewed with fear and trepidation, but they are becoming more commonplace in industry today. The idea of a friendly robot companion has captured our imagination, leading to robots that can interact naturally with people, though their capabilities are still limited compared to how they appear in fiction. As robots become increasingly intelligent and autonomous there are ethical implications that must be taken into account before it's too late; including consideration of moral agency, responsibility and cross-cultural differences when granting them autonomy over decisions made involving human safety.
block 5: The Uber crash in Arizona has highlighted the complexities of allocating responsibility for autonomous robots, raising questions about whether morality can be instilled in robots and if they can take responsibility. The article discusses how many parties involved (e.g., company, car manufacturer, pedestrian) could potentially be responsible for the accident and explores challenges with attributing moral agency to autonomous robots.